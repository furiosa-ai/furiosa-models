{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigating Models from FuriosaAI Model Zoo\n",
    "\n",
    "## FuriosaAI's Software Stack\n",
    "\n",
    "FuriosaAI's software stack caters to a diverse range of deep learning models, with a primary focus on vision-related tasks. Within this stack, the FuriosaAI Compiler optimizes Deep Neural Network (DNN) models and generates executable code for the FuriosaAI NPU. It currently supports TFLite and ONNX models, utilizing the latest research and methods for optimization. The compiler efficiently accelerates various vision-related operators on the NPU while utilizing the CPU for unsupported operations.\n",
    "\n",
    "## Vision Models and Beyond\n",
    "\n",
    "FuriosaAI's first-generation NPU, Warboy, is specialized for vision-related tasks. It accelerates popular vision models like ResNet50, SSD-MobileNet, and EfficientNet, while also enabling users to create custom models that utilize supported operators. This flexibility ensures the generation of highly optimized NPU-ready code for various vision tasks.\n",
    "\n",
    "## Exploring Vision Models\n",
    "\n",
    "For easy exploration of vision models tailored for FuriosaAI's NPU, navigate to the `furiosa.models.vision` module. Here, you'll find a curated selection of models that have been optimized for efficient deployment on the FuriosaAI Warboy NPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EfficientNetB0', 'EfficientNetV2s', 'ResNet50', 'SSDMobileNet', 'SSDResNet34', 'YOLOv5l', 'YOLOv5m']\n"
     ]
    }
   ],
   "source": [
    "from furiosa.models import vision\n",
    "\n",
    "\n",
    "# List of available vision models\n",
    "print(dir(vision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, use the Command line tool to list models\n",
    "! furiosa-models list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   Model name    |      Model description       |      Task type       | Available postprocesses |\n",
    "|-----------------|------------------------------|----------------------|-------------------------|\n",
    "|    ResNet50     |   MLCommons ResNet50 model   | Image Classification |         Python          |\n",
    "|  SSDMobileNet   | MLCommons MobileNet v1 model |   Object Detection   |      Python, Rust       |\n",
    "|   SSDResNet34   | MLCommons SSD ResNet34 model |   Object Detection   |      Python, Rust       |\n",
    "|     YOLOv5l     |      YOLOv5 Large model      |   Object Detection   |          Rust           |\n",
    "|     YOLOv5m     |     YOLOv5 Medium model      |   Object Detection   |          Rust           |\n",
    "| EfficientNetB0  |    EfficientNet B0 model     | Image Classification |         Python          |\n",
    "| EfficientNetV2s |    EfficientNetV2-s model    | Image Classification |         Python          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's instantiate a Model class from vision models and delve deeper into its attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='ResNet50' task_type=<ModelTaskType.IMAGE_CLASSIFICATION: 'IMAGE_CLASSIFICATION'> format=<Format.ONNX: 'ONNX'> family='ResNet' version='v1.5' metadata=Metadata(description='ResNet50 v1.5 int8 ImageNet-1K', publication=Publication(authors=None, title=None, publisher=None, date=None, url='https://arxiv.org/abs/1512.03385.pdf')) tags=None\n",
      "Static fields: ['name', 'task_type', 'format', 'family', 'version', 'metadata', 'tags', 'preprocessor', 'postprocessor']\n",
      "Lazy loaded fields: ['origin', 'tensor_name_to_range']\n"
     ]
    }
   ],
   "source": [
    "model = vision.ResNet50()\n",
    "print(model)\n",
    "\n",
    "# Display the static fields of the model\n",
    "print(\"Static fields:\", list(model.model_fields.keys()))\n",
    "\n",
    "# Show the lazy-loaded fields of the model\n",
    "print(\"Lazy loaded fields:\", list(model.model_computed_fields.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libfuriosa_hal.so --- v0.11.0, built @ 43c901f\n",
      "name: ResNet50\n",
      "format: ONNX\n",
      "family: ResNet\n",
      "version: v1.5\n",
      "metadata:\n",
      "  description: ResNet50 v1.5 int8 ImageNet-1K\n",
      "  publication:\n",
      "    url: https://arxiv.org/abs/1512.03385.pdf\n",
      "task type: Image Classification\n",
      "available postprocess versions: Python\n"
     ]
    }
   ],
   "source": [
    "# Moreover, you can access informative static fields using the Command line tool:\n",
    "! furiosa-models desc ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire the ENF Binary with `model_source()`\n",
    "\n",
    "FuriosaAI's Model object offers a method called `model_source()` which allows you to obtain the ENF (FuriosaAI Compiler-specific format) binary for a specific model. This ENF binary can be directly used for further processing or deployment without the need for recompilation. This is particularly beneficial when you want to save time and resources associated with the compilation process.\n",
    "\n",
    "Using `model_source()` is straightforward. You call this method on a Model object and, as a result, you receive the ENF binary. The `num_pe` parameter, which has a default value of 2, specifies the number of processing elements (PE) to use. You can set it to 1 if you want to use a single PE for the model. This flexibility allows you to optimize the model's deployment according to your specific requirements, whether it's for single-PE or fusioned-PE scenarios.\n",
    "\n",
    "Here's an example of how to use `model_source()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libfuriosa_hal.so --- v0.11.0, built @ 43c901f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":-) Finished in 0.000006756s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorDesc(shape=(1, 3, 224, 224), dtype=UINT8, format=NCHW, size=150528, len=150528)]\n"
     ]
    }
   ],
   "source": [
    "from furiosa.runtime.sync import create_runner\n",
    "\n",
    "model_source = model.model_source(num_pe=2)\n",
    "\n",
    "# Create a runner with the model source\n",
    "with create_runner(model_source) as runner:\n",
    "    # Print model inputs metadata\n",
    "    print(runner.model.inputs())\n",
    "    # Run inferences, ...\n",
    "    ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
